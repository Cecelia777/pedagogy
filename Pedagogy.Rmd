---
title: "Pedagogy"
author: "Cecelia Fu, Hannah Plothow"
date: "2/6/2022"
output: pdf_document

abstract: In this analysis, we used data from 10 semesters of introductory statistics classes to evaluate which activities enhanced student performanceâ€”as measured by the final exam score per semester. We analyzed certain activities (i.e., homework scores, quiz scores, and exam scores) to evaluate which activities lead to higher final exam scores. We found that homework scores and exam scores had the greatest significant impact on final exam scores. Quizzes did not have a significant impact on student learning.
---

# Summary: 



# Introduction:
Every year, thousands of students enter their university of choice with the hopes of growing their knowledge and skill set. Universities, in turn, do their best to make sure they are helping their students learn effectively. Since universities have limited resources, they have to allocate their time and energy into the right sources. This means excluding certain activities if it does not significantly contribute to student growth.  
Our analysis takes data from multiple semesters of an introductory statistics class. We are going to look at the following variables to see their effect on the average final exam score per semester:  


 Variable Names | Description
 ---------------|-----------------
NStudents | The number of students who completed the course  
Exam1 | The average score (in percent) on Exam 1  
Exam2 | The average score (in percent) on Exam 2  
Exam3 | The average score (in percent) on Exam 3  
HW | The average score (in percent) on the homework  
Quiz | The average score (in percent) on class quizzes  
Semester | The semester when the course was given  




```{r, echo = FALSE, warning=FALSE, include = FALSE}
library("tidyverse")
library("ggplot2")
library("lubridate")
library("dplyr")
library("tidyverse")
library("ggplot2")
library("GGally")
library("car")
library("MASS")
library("lmtest")
library("multcomp")
library("nlme")
```


```{r read_data, echo = FALSE, results='hide'}
# Read in data
pedagogy <- read.csv("ClassAssessment.txt", header = TRUE, sep = " ")
head(pedagogy)
#sum(is.na(pedagogy))
# change Semester type
pedagogy$Semester <- as.character(pedagogy$Semester)
var(pedagogy$Final)
#pedagogy$avgExam <- (pedagogy$Exam1 + pedagogy$Exam2 + pedagogy$Exam3)/3
f <- var(pedagogy$Final * pedagogy$NStudents)/pedagogy$NStudents^2
m <- matrix(diag(f), ncol = 30)

g <- var(pedagogy$Final)/pedagogy$NStudents
d <- 1/pedagogy$NStudents

```


```{r eda, echo = FALSE, message = FALSE, out.width='50%'}
par(mfrow = c(2, 2))

ggplot(data = pedagogy, mapping = aes(x = Exam1, y = Final)) + 
  geom_point() + 
  geom_smooth(method = "lm")

ggplot(data = pedagogy, mapping = aes(x = Exam2, y = Final)) + 
  geom_point() + 
  geom_smooth(method = "lm")

ggplot(data = pedagogy, mapping = aes(x = Exam3, y = Final)) + 
  geom_point() + 
  geom_smooth(method = "lm")

ggplot(data = pedagogy, mapping = aes(x = HW, y = Final)) + 
  geom_point() + 
  geom_smooth(method = "lm")

ggplot(data = pedagogy, mapping = aes(x = Quiz, y = Final)) + 
  geom_point() + 
  geom_smooth(method = "lm")

#ggplot(data = pedagogy, mapping = aes(x = avgExam, y = Final)) + 
#  geom_point() + 
#  geom_smooth(method = "lm")

ggplot(data = pedagogy, mapping = aes(x = Semester, y = Final)) + 
  geom_boxplot()


```


> Before we begin our modeling process, we need to look into potential issues that could negatively affect our results. First, our response variable is the average final exam score per semester. One issue that we could run into is equal variance among the residuals. Since each semester has a different number of students, the variance among final exams scores will vary. Since equal variance is one of the assumptions necessary to conduct linear regression, we will have to account for this heteroscedasticity  

> If we choose to ignore this potential problem and not account for the difference in variance, our residual error terms will likely be inaccurate, thus throwing off our model's results. In order to combat heteroscedasticity, we will use a Linear Model weighted by the number of students for each class. 


# Section 2: Statistical Model
$$ y \sim MVN(X\beta, \sigma^2D)$$ 

$$ var(\bar{y}) = \frac{\sigma^2}{NStudents}$$

$$D = \begin{bmatrix}
\frac{1}{819}&0&0&...&0\\
0&\frac{1}{299}&0&...&0\\
0&0&\frac{1}{338}&...&0\\
0&0&0&...&\frac{1}{321}
\end{bmatrix}$$


Our data follows multivariate normal distribution  
Our model uses heteroskedastic multiple linear regression  
y - The actual average final score for the semester  
X - The matrix with our data points including the first column of 1s as our intercept   
$\beta$ - The estimate coefficents  
$\sigma^2$ - The average final score variance for each class  
D - The weights on each class, since each class have different number of students, which the diagonal elements are $\frac{1}{NStudents}$  

For our model to perform as its best ability, the model needs to follow four assumptions below: 
> Linearity: A linear relationship needs to exist between the predictor variables(Exam1, Exam2, Exam3, HW, Quiz, NStudents) and the target(Final).  
>  
> Independence: Each individual data point(Final score for each class) must have little to no effect.  
>  
> Normality: The residuals needs to follow a normal distribution  
>  
> Equal Variance: Residuals need to have constant variance throughout the model  
>  

```{r, model, results='hide',message=FALSE, echo = FALSE}
# homoskedastic linear model
pedagogy.lm <- lm(Final ~ Exam1 + Exam2 + Exam3 + HW + Quiz + NStudents + Semester, weights = NStudents, data = pedagogy)
summary(pedagogy.lm)
anova(pedagogy.lm)
pedagogy$residuals <- pedagogy.lm$residuals
pedagogy$fitted.value <- pedagogy.lm$fitted.values
```

```{r, echo=FALSE, results='hide'}
confint(pedagogy.lm, level = 0.95)
```

```{r}
pedagogy.lm2 <- lm(Final ~ Exam1 + Exam2 + Exam3 + HW + Quiz + NStudents, weights = NStudents, data = pedagogy)
summary(pedagogy.lm2)
```



```{r, echo = FALSE, results='hide'}
anova(pedagogy.lm, pedagogy.lm2)
```



# Section 3: Model Validation  

### Linearity


```{r, assumption_linearity,message=FALSE, echo = FALSE}
# homoscedastic linear model assumption check

# Check for linearity
avPlots(pedagogy.lm)
```
 > Based on the AVPlots, we can see that there is a fairly strong, positive, and linear relationship between the explanatory variables and response variables. There are no curves or trends in the data
> The linearity assumption is met.  

### Independence  
> For this data set, we are going to assume that each individual's score on each assignment was done independent of any other person. Since it is usually against university policy to copy someone else's homework and/or collaborate with someone on an exam, we can assume that the independence assumption is met.  

### Normality
```{r, assumption_normality ,message=FALSE, echo = FALSE}
#ggplot()+geom_histogram(mapping=aes(x=stdres(pedagogy.lm)))

#Verify Standardized Residuals through KS test
normality <- ks.test(stdres(pedagogy.lm), "pnorm")
norm.p <- round(normality$p.value,2)
```

>KS Test  
H0: The data follow a normal distribution  
HA: The data does not follow a normal distribution  
  
>With a p-value of `r norm.p` on the KS test, we fail to reject the Null Hypothesis and assume that the normality assumption is met.  

### Equal Variance
```{r, assumption_equal_variance, message=FALSE, echo = FALSE}
ggplot(data=pedagogy, mapping=aes(x=fitted(pedagogy.lm),y=resid(pedagogy.lm))) + geom_point()

equ_var <- bptest(pedagogy.lm)
equ.p <- round(equ_var$p.value, 2)
```

>A scatter plot of the fitted vs. residuals shows a cloud-like formation with no trends or patterns. This suggests equal variance.    

>BP Test  
H0: The data has equal variance  
HA: The data does not have equal variance  
>  
>This assumption is also confirmed by running a BP Test. With a p-value of `r equ.p`, we can reject the Null Hypothesis and assume that the Equal Variance Assumption is met.













```{r, assumption_check,message=FALSE, echo = FALSE}
# homoskedastic linear model assumption check

# Check for linearity
avPlots(pedagogy.lm)

# Check for independent
# The final score of each semester is independent from each other

# Check for equal variance assumption(equal variance is not met)
ggplot(data = pedagogy.lm, aes(x = fitted(pedagogy.lm), y = resid(pedagogy.lm))) + 
  geom_point() 

#autoplot(pedagogy.lm, which = 1) 

bptest(pedagogy.lm)

# Check for residual of mean of zero (residuals of mean zero is not met)
ggplot() + 
  geom_histogram(mapping = aes(x=stdres(pedagogy.lm)))

ggplot(data = pedagogy, mapping = aes(y=residuals)) + 
  geom_boxplot()

ggplot(data = pedagogy, mapping = aes(x = residuals)) + 
  geom_histogram(mapping = aes(y = ..density..)) 
ks.test(stdres(pedagogy.lm), "pnorm")
```


```{r, model2, results='hide',message=FALSE, echo = FALSE}
# Heteroskedastic model
#pedagogy.gls <- gls(model = Final ~ log(Exam1 + Exam2 + Exam3 + Quiz + HW), data = pedagogy, weights = varExp(form = ~ log(Exam1 + Exam2 + Exam3 + Quiz + HW)), method = "ML")
#plot(pedagogy.gls)

pedagogy.gls <- gls(model = Final ~ (Exam1 + Exam2 + Exam3 + Quiz + HW + NStudents), data = pedagogy, weights = varFixed(value=~ 1/NStudents), method = "ML")
#plot(pedagogy.gls)
summary(pedagogy.gls)
```



```{r, assumption_check2,message=FALSE, echo = FALSE}
# Check for assumption 
ggplot(data = pedagogy, mapping = aes(x = fitted(pedagogy.gls), y = resid(pedagogy.gls, type = "pearson"))) +
  geom_point() + 
  geom_smooth(method = "lm")


# Normality
ggplot() + 
  geom_histogram(mapping=aes(x=resid(pedagogy.gls, type = "pearson")))

# Equal variance??
ggplot(data = pedagogy, mapping = aes(x = fitted(pedagogy.gls), y = resid(pedagogy.gls, type = "pearson"))) +
  geom_point() + 
  geom_smooth()
```


```{r, cv_lm, message=FALSE, warning=FALSE, echo = FALSE}
#source("predictgls.R")

n <- nrow(pedagogy)
#n.cv <- 1000 #Number of CV studies to run
#n.test <- round(.2*n) #Number of observations in a test set
rpmse <- rep(x=NA, times=n)
bias <- rep(x=NA, times=n)
wid <- rep(x=NA, times=n)
cvg <- rep(x=NA, times=n)
for(cv in 1:n){
  ## Select test observations
  #test.obs <- sample(x=1:n, size=n.test)
  
  ## Split into test and training sets
  train.set <- pedagogy[-cv,]
  test.set <- pedagogy[cv,]
  
  
  ## Fit a lm() using the training data
  train.lm <- lm(Final ~ Exam1 + Exam2 + Exam3 + HW + Quiz + NStudents + Semester, data = pedagogy, weights = NStudents)
  
  ## Generate predictions for the test set
  my.preds <- predict.lm(train.lm, newdata=test.set,interval = "prediction")
  
  ## Calculate bias
  bias[cv] <- mean((my.preds[,1])-test.set[['Final']])
  
  ## Calculate RPMSE
  rpmse[cv] <- (test.set$Final- my.preds[,1])^2 %>% mean() %>% sqrt()
  
  ## Calculate Coverage
  cvg[cv] <- ((test.set[['Final']] > my.preds[,2]) & (test.set[['Final']] < my.preds[,3])) %>% mean()
  
  ## Calculate Width
  wid[cv] <- (my.preds[,3] - my.preds[,2]) %>% mean()
  
}


ggplot(mapping = aes(x = bias)) + geom_histogram()
ggplot(mapping = aes(x = rpmse)) + geom_histogram()
#ggplot(mapping = aes(x = cvg)) + geom_histogram()
ggplot(mapping = aes(x = wid)) + geom_histogram()

sd(pedagogy$Final*pedagogy$NStudents)
mean(bias)
mean(rpmse)
mean(cvg)
mean(wid)
```




```{r, cv_gls, results='hide', echo = FALSE}
source("predictgls.R")


n <- nrow(pedagogy)
n.cv <- 100 #Number of CV studies to run
n.test <- round(.2*n) #Number of observations in a test set
rpmse <- rep(x=NA, times=n.cv)
bias <- rep(x=NA, times=n.cv)
wid <- rep(x=NA, times=n.cv)
cvg <- rep(x=NA, times=n.cv)
for(cv in 1:n.cv){
  ## Select test observations
  test.obs <- sample(x=1:n, size=n.test)
  
  ## Split into test and training sets
  test.set <- pedagogy[test.obs,]
  train.set <- pedagogy[-test.obs,]
  
  ## Fit a lm() using the training data
  train.lm <- gls(model = Final ~ (Exam1 + Exam2 + Exam3 + Quiz + HW + Semester + NStudents), data = pedagogy, weights = varFixed(value=~ 1/NStudents), method = "ML")
  
  ## Generate predictions for the test set
  my.preds <- predictgls(glsobj = train.lm, newdframe =test.set , level = 0.95)
  
  ## Calculate bias
  bias[cv] <- mean(my.preds[["Prediction"]]-test.set[['Final']])
  
  ## Calculate RPMSE
  rpmse[cv] <- (test.set$Final-my.preds[["Prediction"]])^2 %>% mean() %>% sqrt()
  
  ## Calculate Coverage
  cvg[cv] <- ((test.set[['Final']] > my.preds[["lwr"]]) & (test.set[['Final']] < my.preds[["upr"]])) %>% mean()
  
  ## Calculate Width
  wid[cv] <- (my.preds[["upr"]] - my.preds[["lwr"]]) %>% mean()
  
}


ggplot(mapping = aes(x = bias)) + geom_histogram()
mean(bias)
ggplot(mapping = aes(x = rpmse)) + geom_histogram()
mean(rpmse)
ggplot(mapping = aes(x = cvg)) + geom_histogram()
mean(cvg)
ggplot(mapping = aes(x = wid)) + geom_histogram()
mean(wid)
```





# Section 4: Analysis Results

```{r, echo = FALSE}
#summary(pedagogy.lm)
```
Explanatory Variable|P-Value
--------------------|---------
Exam1      | 0.03108 *  
Exam2      | 0.00262 ** 
Exam3      | 8.39e-09 ***
HW         | 0.05445 .  
Quiz       | 0.61195    
NStudents  | 0.78409    
Semester10 | 0.19601    
Semester2  | 0.33229    
Semester3  | 0.71020    
Semester4  | 0.55790    
Semester5  | 0.61206    
Semester6  | 0.66474    
Semester7  | 0.74845    
Semester8  | 0.26301    
Semester9  | 0.89765

Based on the table above, we can see that there are three main variables that significantly impacted the average final exam score: Exam 1, Exam 2, and Exam 3. Homework scores, while technically not significant, still had a very low p-value of .054. Out of every activity, Exam 3 had the highest impact.  
  
Based on our analysis, Quiz scores, number of students per class, and semester didn't have a significant impact on the average final exam score.  
  
Currently, it appears that these classes are doing a good job helping students perform well. They include activities that boost their final exam scores. None of the semesters had a significant impact on the average final exam score. Using Semester 1 as a baseline, our analysis shows that semester 10 performed the best, with their average scores being better than semester 1 by .414. Semester 8 performed the worst with their average scores being .377 lower than Semester 1.

# Section 5: Conclusions

Based on our analysis, we can see that this university is doing a good job with their introductory statistics classes. They include activities that effectively increase student knowledge.   

Going forward, the university might want to take a closer look at whether or not quizzes are worth including in the class curriculum. Our analysis showed that quizzes did not significantly affect the average final exam score, thus implying that it did not contribute to increasing the students' understanding of the material. However, there are other factors to consider when deciding to remove or keep the quizzes. If the quizzes are used as an incentive to come to class, that might have an effect on student learning that we were unable to capture in this analysis.  

Another thing to look at would be Exam 1. Exams 2 and 3 were highly significant in measuring student success. However, Exam 1 was only moderately significant. The department might want to take a closer look at Exam 1 to see what can be improved.











## Apendix B: Code
```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```

